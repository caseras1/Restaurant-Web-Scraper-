{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f7248c7-3d74-42b9-8ec9-a828dc2c907b",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax. Perhaps you forgot a comma? (cuisine_keywords.py, line 362)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[1;36m(most recent call last)\u001b[0m:\n",
      "\u001b[0m  File \u001b[0;32m~\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3577\u001b[0m in \u001b[0;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\u001b[0m\n",
      "\u001b[1;36m  Cell \u001b[1;32mIn[6], line 6\u001b[1;36m\n\u001b[1;33m    from cuisine_keywords import cuisine_keywords  # External Python file containing the keyword dictionary\u001b[1;36m\n",
      "\u001b[1;36m  File \u001b[1;32m~\\Python Webscraper\\cuisine_keywords.py:362\u001b[1;36m\u001b[0m\n\u001b[1;33m    \"South American\": {\u001b[0m\n\u001b[1;37m                      ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from cuisine_keywords import cuisine_keywords  # External Python file containing the keyword dictionary\n",
    "from unidecode import unidecode  # Normalize accented characters\n",
    "\n",
    "# === CONFIG ===\n",
    "API_KEY = \"AIzaSyBPXacrTdwVOZ8vS6nlywLkD3D49Yipz2Q\"\n",
    "SEARCH_URL = \"https://maps.googleapis.com/maps/api/place/textsearch/json\"\n",
    "DETAILS_URL = \"https://maps.googleapis.com/maps/api/place/details/json\"\n",
    "CSV_INPUT = \"haarlem_today_restaurants.csv\"\n",
    "CSV_OUTPUT = \"haarlem_today_fully_enriched.csv\"\n",
    "\n",
    "# === Load model and cuisine labels ===\n",
    "print(\"Loading BERT model...\")\n",
    "model = SentenceTransformer(\"all-mpnet-base-v2\")\n",
    "CUISINES = list(cuisine_keywords.keys())\n",
    "cuisine_embeddings = model.encode(CUISINES, convert_to_tensor=True)\n",
    "\n",
    "# === Read input file ===\n",
    "print(f\"Reading input file: {CSV_INPUT}\")\n",
    "df = pd.read_csv(CSV_INPUT)\n",
    "\n",
    "# Prepare new columns for classification\n",
    "df[\"Cuisine BERT\"] = \"\"\n",
    "df[\"Cuisine Keywords\"] = \"\"\n",
    "df[\"Keyword Score\"] = \"\"\n",
    "df[\"BERT Score\"] = \"\"\n",
    "df[\"Final Cuisine\"] = \"\"\n",
    "df[\"Certainty\"] = \"\"\n",
    "df[\"Final Score\"] = \"\"\n",
    "df[\"Google Type Cuisine\"] = \"\"\n",
    "df[\"Keyword Hits\"] = \"\"\n",
    "\n",
    "# Prepare new columns for Google data\n",
    "df[\"Google Name\"] = \"\"\n",
    "df[\"Rating\"] = \"\"\n",
    "df[\"Total Ratings\"] = \"\"\n",
    "df[\"Google Address\"] = \"\"\n",
    "df[\"Place ID\"] = \"\"\n",
    "df[\"Types\"] = \"\"\n",
    "df[\"Price Level\"] = \"\"\n",
    "df[\"Google Website\"] = \"\"\n",
    "df[\"Phone Number\"] = \"\"\n",
    "df[\"Opening Hours\"] = \"\"\n",
    "\n",
    "def map_price_level(level):\n",
    "    mapping = {\n",
    "        1: \"$\",\n",
    "        2: \"$$\",\n",
    "        3: \"$$$\",\n",
    "        4: \"$$$$\"\n",
    "    }\n",
    "    return mapping.get(level, \"\")\n",
    "\n",
    "# === Main loop ===\n",
    "print(\"Starting data enrichment process...\")\n",
    "for idx, row in df.iterrows():\n",
    "    name = str(row.get(\"Name\", \"\")).strip()\n",
    "    if not name or name.lower() == \"nan\":\n",
    "        continue\n",
    "    \n",
    "    print(f\"Processing {idx+1}/{len(df)}: {name}\")\n",
    "    \n",
    "    query = f\"{name} restaurant Haarlem\"\n",
    "    search_params = {\n",
    "        \"query\": query,\n",
    "        \"region\": \"nl\",\n",
    "        \"location\": \"52.3874,4.6462\",\n",
    "        \"radius\": 30000,\n",
    "        \"key\": API_KEY\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        # === STEP 1: Get basic place data ===\n",
    "        res = requests.get(SEARCH_URL, params=search_params)\n",
    "        data = res.json()\n",
    "        if not data.get(\"results\"):\n",
    "            print(f\"❌ No results for: {query}\")\n",
    "            print(f\"↪️ Response: {data.get('status')} {data.get('error_message', '')}\")\n",
    "            continue\n",
    "\n",
    "        place = data[\"results\"][0]\n",
    "        place_id = place[\"place_id\"]\n",
    "        \n",
    "        # Store basic Google data\n",
    "        df.at[idx, \"Google Name\"] = place.get(\"name\", \"\")\n",
    "        df.at[idx, \"Rating\"] = place.get(\"rating\", \"\")\n",
    "        df.at[idx, \"Total Ratings\"] = place.get(\"user_ratings_total\", \"\")\n",
    "        df.at[idx, \"Google Address\"] = place.get(\"formatted_address\", \"\")\n",
    "        df.at[idx, \"Place ID\"] = place_id\n",
    "        df.at[idx, \"Types\"] = \", \".join(place.get(\"types\", []))\n",
    "        \n",
    "        # === STEP 2: Get detailed place data ===\n",
    "        details_params = {\n",
    "            \"place_id\": place_id,\n",
    "            \"fields\": \"editorial_summary,reviews,types,price_level,website,formatted_phone_number,opening_hours\",\n",
    "            \"key\": API_KEY\n",
    "        }\n",
    "\n",
    "        res = requests.get(DETAILS_URL, params=details_params)\n",
    "        details = res.json().get(\"result\", {})\n",
    "        \n",
    "        # Store additional Google data\n",
    "        raw_price = details.get(\"price_level\")\n",
    "        df.at[idx, \"Price Level\"] = map_price_level(raw_price)\n",
    "        df.at[idx, \"Google Website\"] = details.get(\"website\", \"\")\n",
    "        df.at[idx, \"Phone Number\"] = details.get(\"formatted_phone_number\", \"\")\n",
    "        if details.get(\"opening_hours\"):\n",
    "            df.at[idx, \"Opening Hours\"] = \", \".join(details[\"opening_hours\"].get(\"weekday_text\", []))\n",
    "\n",
    "        # === STEP 3: Cuisine Classification ===\n",
    "        texts = []\n",
    "        if \"editorial_summary\" in details:\n",
    "            texts.append(details[\"editorial_summary\"].get(\"overview\", \"\"))\n",
    "        if \"reviews\" in details:\n",
    "            texts += [r.get(\"text\", \"\") for r in details[\"reviews\"] if \"text\" in r]\n",
    "\n",
    "        combined_text = \" \".join(texts + [name]).lower().strip()\n",
    "        combined_text = unidecode(combined_text)  # Normalize accents\n",
    "\n",
    "        if not combined_text:\n",
    "            continue\n",
    "\n",
    "        # BERT Matching\n",
    "        embedding = model.encode(combined_text, convert_to_tensor=True)\n",
    "        scores = util.cos_sim(embedding, cuisine_embeddings)[0]\n",
    "\n",
    "        # Keyword Matching with regex\n",
    "        match_scores = {}\n",
    "        match_hits = {}\n",
    "\n",
    "        for cuisine, keywords in cuisine_keywords.items():\n",
    "            total_score = 0\n",
    "            hits = []\n",
    "            for kw, weight in keywords.items():\n",
    "                kw_normalized = unidecode(kw.lower())\n",
    "                if re.search(rf\"\\b{re.escape(kw_normalized)}\\b\", combined_text):\n",
    "                    total_score += weight\n",
    "                    hits.append(kw)\n",
    "            if total_score > 0:\n",
    "                match_scores[cuisine] = total_score\n",
    "                match_hits[cuisine] = hits\n",
    "\n",
    "        # Google Type Cuisine Guess\n",
    "        google_types = details.get(\"types\", [])\n",
    "        google_cuisine_guess = None\n",
    "        for t in google_types:\n",
    "            if \"restaurant\" in t and \"_\" in t:\n",
    "                guess = t.split(\"_\")[0].capitalize()\n",
    "                if guess in CUISINES:\n",
    "                    google_cuisine_guess = guess\n",
    "                    break\n",
    "        df.at[idx, \"Google Type Cuisine\"] = google_cuisine_guess if google_cuisine_guess else \"None\"\n",
    "\n",
    "        # Score Fusion\n",
    "        cuisine_scores = {}\n",
    "        for cuisine in CUISINES:\n",
    "            bert_idx = CUISINES.index(cuisine)\n",
    "            bert_score = float(scores[bert_idx])\n",
    "\n",
    "            kw_score = match_scores.get(cuisine, 0)\n",
    "            max_possible = sum(cuisine_keywords[cuisine].values())\n",
    "            kw_norm = kw_score / max_possible if max_possible else 0\n",
    "\n",
    "            fusion_score = (bert_score * 0.6) + (kw_norm * 0.4)\n",
    "            if cuisine == google_cuisine_guess:\n",
    "                fusion_score += 0.1\n",
    "            cuisine_scores[cuisine] = fusion_score\n",
    "\n",
    "        # Final Cuisine Selection\n",
    "        final_cuisine = max(cuisine_scores, key=cuisine_scores.get)\n",
    "        final_score = round(cuisine_scores[final_cuisine], 4)\n",
    "        certainty = \"HIGH\" if final_score > 0.75 else \"MEDIUM\" if final_score > 0.5 else \"LOW\"\n",
    "\n",
    "        # Save debug info\n",
    "        top_bert_idx = int(scores.argmax())\n",
    "        df.at[idx, \"Cuisine BERT\"] = CUISINES[top_bert_idx]\n",
    "        df.at[idx, \"BERT Score\"] = round(float(scores[top_bert_idx]), 10)\n",
    "\n",
    "        if final_cuisine in match_scores:\n",
    "            df.at[idx, \"Cuisine Keywords\"] = f\"{final_cuisine} ({match_scores[final_cuisine]})\"\n",
    "            df.at[idx, \"Keyword Score\"] = match_scores[final_cuisine]\n",
    "            df.at[idx, \"Keyword Hits\"] = \", \".join(match_hits.get(final_cuisine, []))\n",
    "        else:\n",
    "            df.at[idx, \"Cuisine Keywords\"] = \"None\"\n",
    "            df.at[idx, \"Keyword Score\"] = 0\n",
    "            df.at[idx, \"Keyword Hits\"] = \"\"\n",
    "\n",
    "        df.at[idx, \"Final Cuisine\"] = final_cuisine\n",
    "        df.at[idx, \"Certainty\"] = certainty\n",
    "        df.at[idx, \"Final Score\"] = final_score\n",
    "        \n",
    "        print(f\"✅ {name} → Rating: {place.get('rating', 'N/A')}, Cuisine: {final_cuisine} ({certainty})\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error processing {name}: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "    # Be kind to Google's API rate limits\n",
    "    time.sleep(2)  \n",
    "\n",
    "# === Save results ===\n",
    "print(f\"Saving enriched data to {CSV_OUTPUT}\")\n",
    "df.to_csv(CSV_OUTPUT, index=False)\n",
    "print(f\"\\n✅ Saved to {CSV_OUTPUT}\")\n",
    "\n",
    "try:\n",
    "    import ace_tools as tools\n",
    "    tools.display_dataframe_to_user(name=\"Restaurant Enrichment Results\", dataframe=df)\n",
    "except ImportError:\n",
    "    print(\"Note: ace_tools not available, skipping dataframe display\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7a2281-a881-4687-b428-9c1c9f7c7b5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
